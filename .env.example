# Azure AI Foundry project connection string
# Format: <region>.api.azureml.ms;<project_id>;<hub_name>;<project_name>
AZURE_AI_FOUNDRY_PROJECT_CONNECTION_STRING=<region>.api.azureml.ms;<project_id>;<hub_name>;<project_name>
AZURE_AI_FOUNDRY_PROJECT_AGENTS_CONNECTION_STRING=<region>.api.azureml.ms;<project_id>;<hub_name>;<project_name>

# Azure AI Agent with Semantic Kernel (Option 1 - Connection String)
AZURE_AI_AGENT_PROJECT_CONNECTION_STRING=<region>.api.azureml.ms;<project_id>;<hub_name>;<project_name>
AZURE_AI_AGENT_MODEL_DEPLOYMENT_NAME=<your-model-deployment-name>

# Azure AI Foundry Hub details (for explore-your-ai-foundry-hub.ipynb)
AZURE_SUBSCRIPTION_ID=<your-subscription-id>
AZURE_RESOURCE_GROUP=<your-resource-group>
AZURE_AI_FOUNDRY_HUB_NAME=<your-hub-name>

# Azure AI Inference direct connection (for direct inference SDK examples)
AZURE_INFERENCE_ENDPOINT=<your-endpoint-url>  # Example https://<my openai service>.openai.azure.com/openai/deployments/gpt-4o-mini/
AZURE_INFERENCE_API_KEY=<your-api-key>

# Azure AI Services connection
AZURE_AI_SERVICES_ENDPOINT=<your-endpoint-url>  # Example https://<your-endpoint AI services>.cognitiveservices.azure.com/
AZURE_AI_SERVICES_API_KEY=<your-api-key>

# Azure OpenAI connection
AZURE_OPENAI_ENDPOINT=<your-openai-endpoint>  # Example https://<my openai service>.openai.azure.com/
AZURE_OPENAI_DEPLOYMENT=<your-openai-deployment>  # Example gpt-4o-mini
AZURE_OPENAI_KEY=<your-openai-key>
AZURE_OPENAI_API_VERSION=<your-openai-api-version>  # Example 2024-10-21

# Bing Search connection
BING_CONNECTION_NAME=<your-ai-foundry-connected-bing-service>

# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO
