# Azure AI Foundry project connection String
# Format: <region>.api.azureml.ms;<project_id>;<hub_name>;<project_name>
AZURE_AI_FOUNDRY_PROJECT_CONNECTION_STRING=<region>.api.azureml.ms;<project_id>;<hub_name>;<project_name>

# Azure AI Inference direct connection (for 04-direct-inference-sdk-chat-client)
AZURE_INFERENCE_ENDPOINT=<your-endpoint-url>  # Example https://<my openai service>.openai.azure.com/openai/deployments/gpt-4o-mini/
AZURE_INFERENCE_API_KEY=<your-api-key>

# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO
