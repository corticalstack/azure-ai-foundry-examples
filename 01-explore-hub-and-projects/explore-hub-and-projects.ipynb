{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Azure AI Foundry Hub and Projects\n",
    "\n",
    "This notebook explores your Azure AI Foundry hub and associated projects, including:\n",
    "1. Dumping out details of the hub\n",
    "2. Displaying the docstring of the hub class that documents what a hub is\n",
    "3. Listing all the child workspaces of type project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import inspect\n",
    "from IPython.display import display, Markdown, HTML\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.entities._workspace._ai_workspaces.hub import Hub\n",
    "from azure.ai.ml.entities._workspace._ai_workspaces.project import Project\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.mgmt.cognitiveservices import CognitiveServicesManagementClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "# Look for .env in the current directory and parent directory\n",
    "current_dir = Path(__file__).parent.absolute() if '__file__' in globals() else Path().absolute()\n",
    "root_dir = current_dir.parent\n",
    "load_dotenv(dotenv_path=root_dir / \".env\")\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    print(\"✓ Successfully initialized DefaultAzureCredential\")\n",
    "except Exception as e:\n",
    "    print(f\"× Error initializing credentials: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = os.getenv(\"AZURE_SUBSCRIPTION_ID\")\n",
    "resource_group = os.getenv(\"AZURE_RESOURCE_GROUP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hub Class Docstring\n",
    "\n",
    "Check the docstring of the Hub class for an explanation of what an AI Foundry Hub is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_docstring = inspect.getdoc(Hub)\n",
    "print(\"\\n=== Hub Class Documentation:\")\n",
    "print(\"\\n\" + hub_docstring if hub_docstring else \"No docstring available for Hub class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Class Docstring\n",
    "\n",
    "Now check the docstring of the Project class to understand what an AI Foundry project is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_docstring = inspect.getdoc(Project)\n",
    "print(\"\\n==== Project Class Documentation:\")\n",
    "print(\"\\n\" + project_docstring if hub_docstring else \"No docstring available for project class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ml_client(workspace_name):\n",
    "    \"\"\"\n",
    "    Initialize and return an MLClient for the specified workspace.\n",
    "    \n",
    "    Args:\n",
    "        workspace_name: Name of the workspace\n",
    "        \n",
    "    Returns:\n",
    "        MLClient: The initialized client or None if initialization fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not subscription_id or \"<\" in subscription_id:\n",
    "            print(\"× Error: AZURE_SUBSCRIPTION_ID not set or contains placeholder. Please update your .env file.\")\n",
    "            return None\n",
    "        elif not resource_group or \"<\" in resource_group:\n",
    "            print(\"× Error: Resource group not provided or contains placeholder.\")\n",
    "            return None\n",
    "        elif not workspace_name:\n",
    "            print(\"× Error: Workspace name not provided or contains placeholder.\")\n",
    "            return None\n",
    "            \n",
    "        client = MLClient(\n",
    "            credential=credential,\n",
    "            subscription_id=subscription_id,\n",
    "            resource_group_name=resource_group,\n",
    "            workspace_name=workspace_name\n",
    "        )\n",
    "        print(f\"✓ Successfully connected to workspace: {workspace_name}\")\n",
    "        return client\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"× Error connecting to workspace {workspace_name}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_workspace_details(workspace_or_id, ml_client=None, title=None):\n",
    "    \"\"\"Get and display details for a workspace.\"\"\"\n",
    "    if isinstance(workspace_or_id, str):\n",
    "        # handle project\n",
    "        parts = workspace_or_id.split('/') \n",
    "        workspace = ml_client.workspaces.get(\n",
    "            name=parts[8],\n",
    "            resource_group_name=parts[4]\n",
    "        )\n",
    "    else:\n",
    "        # handle hub\n",
    "        workspace = workspace_or_id\n",
    "    \n",
    "    display(Markdown(f\"## {title} Details\"))\n",
    "    data = {\"Property\": [], \"Value\": []}\n",
    "    workspace_dict = workspace._to_dict()\n",
    "\n",
    "    for k, v in sorted(workspace_dict.items()):\n",
    "        data[\"Property\"].append(k)\n",
    "        if isinstance(v, (dict, list)):\n",
    "            data[\"Value\"].append(json.dumps(v, indent=4))\n",
    "        else:\n",
    "            data[\"Value\"].append(str(v))\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    styled_df = df.style.set_properties(**{\n",
    "        'white-space': 'pre-wrap', \n",
    "        'overflow-wrap': 'break-word',\n",
    "        'max-width': '800px'\n",
    "    })\n",
    "    \n",
    "    display(styled_df)\n",
    "    \n",
    "    summary = {\"name\": workspace.name, \"type\": \"Hub\" if isinstance(workspace, Hub) else \"Project\"}\n",
    "    if summary[\"type\"] == \"Hub\" and \"associated_workspaces\" in workspace_dict:\n",
    "        summary[\"child_projects\"] = len(workspace_dict[\"associated_workspaces\"])\n",
    "    elif \"hub_id\" in workspace_dict:\n",
    "        summary[\"parent_hub\"] = workspace_dict[\"hub_id\"].split(\"/\")[-1]\n",
    "        summary[\"discovery_url\"] = workspace_dict[\"discovery_url\"]\n",
    "        summary[\"id\"] = workspace_dict[\"id\"]\n",
    "    \n",
    "    return workspace, workspace_dict, summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate a handle to the AI Foundry Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_name = os.getenv(\"AZURE_AI_FOUNDRY_HUB_NAME\")\n",
    "hub_ml_client = get_ml_client(hub_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Hub\n",
    "Retrieve detailed information about the hub using our helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_info = hub_ml_client.workspaces.get(name=hub_name)\n",
    "hub, hub_dict, hub_summary = get_workspace_details(hub_info, title=\"Hub\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hub connections\n",
    "List the hub connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_list = hub_ml_client.connections.list()\n",
    "for i, conn in enumerate(connection_list):\n",
    "    display(Markdown(f\"##  Connection #{i+1}: {conn.name}\"))\n",
    "    \n",
    "    # Convert to dictionary and pretty print\n",
    "    conn_dict = conn.to_dict() if hasattr(conn, 'to_dict') else vars(conn)\n",
    "    pprint(conn_dict, width=100, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hub projects\n",
    "\n",
    "Now, let's list all the child workspaces of type project associated with this hub using our helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\"## Listing child projects\"))\n",
    "project_summaries = []\n",
    "\n",
    "if hasattr(hub, 'associated_workspaces') and hub.associated_workspaces:\n",
    "    for i, workspace_id in enumerate(hub.associated_workspaces):\n",
    "        workspace, _, summary = get_workspace_details(\n",
    "            workspace_id, \n",
    "            ml_client=hub_ml_client, \n",
    "            title=f\"Project #{i+1}\"\n",
    "        )\n",
    "        if workspace and isinstance(workspace, Project):\n",
    "            project_summaries.append(summary)\n",
    "    \n",
    "    if project_summaries:\n",
    "        display(Markdown(f\"### Projects summary\"))\n",
    "        projects_df = pd.DataFrame(project_summaries)\n",
    "        display(projects_df)\n",
    "        display(Markdown(f\"### Total Projects: {len(project_summaries)}\"))\n",
    "else:\n",
    "    display(Markdown(f\"### No associated workspaces found.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore project connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\"## Exploring Project Connections\"))\n",
    "for project in project_summaries:\n",
    "    discovery_url = project.get(\"discovery_url\", \"\")\n",
    "    project_id = project.get(\"id\", \"\")\n",
    "    project_name = project.get(\"name\", \"\")\n",
    "    \n",
    "    if not discovery_url or not project_id:\n",
    "        print(f\"× Skipping project {project_name} due to missing discovery_url or id\")\n",
    "        continue\n",
    "    \n",
    "    # Extract different parts of connection config to assemble the connection string\n",
    "    hostname = discovery_url.replace(\"https://\", \"\").replace(\"/discovery\", \"\")\n",
    "    id_parts = project_id.split('/')\n",
    "    subscription_id = id_parts[2] if len(id_parts) > 2 else \"\"\n",
    "    resource_group = id_parts[4] if len(id_parts) > 4 else \"\"\n",
    "    \n",
    "    conn_str = f\"{hostname};{subscription_id};{resource_group};{project_name}\"\n",
    "    \n",
    "    display(Markdown(f\"### Project: {project_name}\"))\n",
    "    print(f\"Connection String: {conn_str}\")\n",
    "    \n",
    "    try:\n",
    "        project_client = AIProjectClient.from_connection_string(\n",
    "            conn_str=conn_str,\n",
    "            credential=credential\n",
    "        )\n",
    "        \n",
    "        # Get connections for this project\n",
    "        connections = project_client.connections.list()\n",
    "        display(Markdown(f\"### Connections for {project_name} (found {len(connections)}):\"))\n",
    "        \n",
    "        for i, connection in enumerate(connections):\n",
    "            display(Markdown(f\"#### Connection #{i+1}: {connection.name}\"))\n",
    "            conn_dict = connection.to_dict() if hasattr(connection, 'to_dict') else vars(connection)\n",
    "            pprint(conn_dict, width=100, sort_dicts=False)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"× Error working with project {project_name}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Project Service Deployments\n",
    "Use CognitiveServicesManagementClient to get the project model deployments deployed as cognitive services resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_service_deployments(cognitive_client, resource_group_name, account_name):\n",
    "    \"\"\"Get deployments for a cognitive services account and return as a list of dictionaries.\"\"\"\n",
    "    try:\n",
    "        deployments = cognitive_client.deployments.list(resource_group_name, account_name)\n",
    "        deployment_list = []\n",
    "        \n",
    "        for deployment in deployments:\n",
    "            deployment_info = {\n",
    "                \"Account\": account_name,\n",
    "                \"Deployment\": deployment.name,\n",
    "                \"Model\": deployment.properties.model.name,\n",
    "                \"Scale Type\": deployment.sku.name,\n",
    "                \"Scale Size\": deployment.sku.capacity\n",
    "            }\n",
    "            deployment_list.append(deployment_info)\n",
    "            \n",
    "        return deployment_list\n",
    "    except Exception as e:\n",
    "        print(f\"× Error listing deployments for account {account_name}: {str(e)}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\"###  Cognitive Services Accounts and Deployments\"))\n",
    "\n",
    "try:\n",
    "    all_deployments = []\n",
    "    \n",
    "    cognitive_client = CognitiveServicesManagementClient(credential, subscription_id)\n",
    "    accounts = cognitive_client.accounts.list()\n",
    "\n",
    "    for account in accounts:\n",
    "        resource_group_name = account.id.split('/')[4]\n",
    "        account_name = account.name\n",
    "        account_type = account.kind\n",
    "        account_location = account.location\n",
    "        account_endpoint = account.properties.endpoint\n",
    "        \n",
    "        # Get deployments for this account\n",
    "        deployments = list_service_deployments(cognitive_client, resource_group_name, account_name)\n",
    "        \n",
    "        # If no deployments were found, add the account info anyway\n",
    "        if not deployments:\n",
    "            all_deployments.append({\n",
    "                \"Account\": account_name,\n",
    "                \"Type\": account_type,\n",
    "                \"Location\": account_location,\n",
    "                \"Endpoint\": account_endpoint,\n",
    "                \"Deployment\": \"N/A\",\n",
    "                \"Model\": \"N/A\",\n",
    "                \"Scale Type\": \"N/A\",\n",
    "                \"Scale Size\": \"N/A\"\n",
    "            })\n",
    "        else:\n",
    "            for deployment in deployments:\n",
    "                deployment[\"Type\"] = account_type\n",
    "                deployment[\"Location\"] = account_location\n",
    "                deployment[\"Endpoint\"] = account_endpoint\n",
    "                all_deployments.append(deployment)\n",
    "    \n",
    "    if all_deployments:\n",
    "        df = pd.DataFrame(all_deployments)\n",
    "        styled_df = df.style.set_properties(**{\n",
    "            'white-space': 'pre-wrap',\n",
    "            'overflow-wrap': 'break-word',\n",
    "            'max-width': '800px'\n",
    "        })\n",
    "        display(styled_df)\n",
    "    else:\n",
    "        print(\"No cognitive services accounts or deployments found.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"× Error listing cognitive services accounts: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
