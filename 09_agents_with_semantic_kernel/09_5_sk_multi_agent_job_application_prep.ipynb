{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-agent preparation for job application and interview\n",
    "This example demonstrates a Semantic Kernel Agents solution to: \n",
    "- upload a candidate resume (or use a mock)\n",
    "- scrape an open job position from a web url (or use a mock)\n",
    "- update a candidate resume to target it to the open job position\n",
    "- prepare a set of interview questions to support the candidate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup\n",
    "First, import the necessary libraries and do some setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import logging\n",
    "import yaml\n",
    "import requests\n",
    "import requests\n",
    "import logging\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "from typing import Annotated\n",
    "\n",
    "from semantic_kernel.kernel import Kernel\n",
    "from semantic_kernel.contents import ChatHistoryTruncationReducer\n",
    "from semantic_kernel.contents.chat_message_content import ChatMessageContent\n",
    "from semantic_kernel.contents.utils.author_role import AuthorRole\n",
    "from semantic_kernel.functions import kernel_function, KernelArguments, KernelPlugin, KernelFunctionFromPrompt\n",
    "from semantic_kernel.agents import ChatCompletionAgent, AgentGroupChat\n",
    "from semantic_kernel.agents.strategies.termination.termination_strategy import TerminationStrategy\n",
    "from semantic_kernel.agents.strategies import KernelFunctionSelectionStrategy, KernelFunctionTerminationStrategy\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatPromptExecutionSettings\n",
    "from semantic_kernel.connectors.ai.azure_ai_inference import AzureAIInferenceChatCompletion\n",
    "from semantic_kernel.connectors.ai.function_choice_behavior import FunctionChoiceBehavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set higher logging level for the azure libraries to suppress verbose HTTP logs, so we can focus on Semantic Kernel logs\n",
    "logging.getLogger(\"azure\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"azure.core.pipeline.policies.http_logging_policy\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "# Look for .env in the current directory and parent directory\n",
    "current_dir = pathlib.Path().absolute()\n",
    "root_dir = current_dir.parent\n",
    "load_dotenv(dotenv_path=root_dir / \".env\")\n",
    "\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "AZURE_OPENAI_API_KEY=os.getenv(\"AZURE_OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Model Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT4O_SERVICE = AzureAIInferenceChatCompletion(\n",
    "    ai_model_id=\"gpt-4o\",\n",
    "    endpoint=f\"{str(AZURE_OPENAI_ENDPOINT).strip('/')}/openai/deployments/{AZURE_OPENAI_DEPLOYMENT_NAME}\",\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Kernel Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEB_JOB_RESEARCH_AGENT_NAME = \"Web-Job-Research-Agent\"\n",
    "RESUME_COPYWRITER_AGENT_NAME = \"Resume-Copywriter-Agent\"\n",
    "RESUME_REVIEWER_AGENT_NAME = \"Resume-Reviewer-Agent\"\n",
    "INTERVIEW_PREPARATION_AGENT_NAME = \"Interview-Preparation-Agent\"\n",
    "\n",
    "RESUME_REVIEW_CONTINUE_KEYWORD = \"RESUME_REVIEW_CONTINUE\"\n",
    "RESUME_REVIEW_COMPLETE_KEYWORD = \"RESUME_REVIEW_COMPLETE\"\n",
    "INTERVIEW_PREP_NEEDED = \"INTERVIEW_PREP_NEEDED\"\n",
    "TERMINATION_KEYWORD = \"PROCESS_COMPLETE\"\n",
    "PROCESS_COMPLETE = \"COMPLETE\"\n",
    "\n",
    "MAXIMUM_CHAT_ITERATIONS=12\n",
    "MAXIMUM_HISTORY_MESSAGES=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Sources Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_MOCK_JOB_POSTING = True\n",
    "MOCK_JOB_POSTING_PATH = \"09_5_mock_job_posting.txt\"\n",
    "JOB_POSTING_URL = \"https://jobs.lever.co/AIFund/29e4750a-61c1-4195-9a11-7889577e3d6f\"\n",
    "JOB_POSTING_MAX_LENGTH = 8000  # Adjust based on LLM's context window size\n",
    "\n",
    "RESUME_PATH = \"09_5_mock_resume.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure 3 Pillars of Observability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opentelemetry.sdk.resources import Resource\n",
    "from opentelemetry.semconv.resource import ResourceAttributes\n",
    "from opentelemetry._logs import set_logger_provider\n",
    "from opentelemetry.metrics import set_meter_provider\n",
    "from opentelemetry.trace import set_tracer_provider, get_tracer\n",
    "\n",
    "from opentelemetry.sdk.trace import TracerProvider, ReadableSpan\n",
    "from opentelemetry.sdk.trace.export import BatchSpanProcessor\n",
    "from opentelemetry.sdk.metrics import MeterProvider\n",
    "from opentelemetry.sdk.metrics.export import PeriodicExportingMetricReader\n",
    "from opentelemetry.sdk.metrics.view import DropAggregation, View\n",
    "from opentelemetry.sdk._logs import LoggerProvider, LoggingHandler\n",
    "from opentelemetry.sdk._logs.export import BatchLogRecordProcessor\n",
    "\n",
    "from azure.monitor.opentelemetry.exporter import (\n",
    "    AzureMonitorLogExporter,\n",
    "    AzureMonitorMetricExporter,\n",
    "    AzureMonitorTraceExporter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSpanProcessor(BatchSpanProcessor):\n",
    "    \"\"\"Filtering out spans with specific names and URLs to keep only Semantic Kernel telemetry\"\"\"\n",
    "\n",
    "    EXCLUDED_SPAN_NAMES = ['.*CosmosClient.*', '.*DatabaseProxy.*', '.*ContainerProxy.*']\n",
    "\n",
    "    def on_end(self, span: ReadableSpan) -> None:\n",
    "       \n",
    "        for regex in self.EXCLUDED_SPAN_NAMES:\n",
    "            if re.match(regex, span.name):\n",
    "                return\n",
    "            \n",
    "        if span.attributes.get('component') == 'http':\n",
    "            return\n",
    "    \n",
    "        super().on_end(span)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up tracing\n",
    "To inspect telemetry data, navigate to your Application Insights resource in the Azure portal, then navigate to the **Transactions search** tab to view the traced transactions, once the agent workload has completed. For more info, see:\n",
    "\n",
    "https://learn.microsoft.com/en-us/semantic-kernel/concepts/enterprise-readiness/observability/telemetry-with-app-insights?tabs=Powershell&pivots=programming-language-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up tracing\n",
    "exporters = []\n",
    "exporters.append(AzureMonitorTraceExporter.from_connection_string(os.getenv(\"APPLICATIONINSIGHTS_CONNECTION_STRING\")))\n",
    "telemetry_resource = Resource.create({ResourceAttributes.SERVICE_NAME: os.getenv(\"AZURE_RESOURCE_GROUP\",\"rg-ai-services-core\")})\n",
    "\n",
    "tracer_provider = TracerProvider(resource=telemetry_resource)\n",
    "for trace_exporter in exporters:\n",
    "    tracer_provider.add_span_processor(CustomSpanProcessor(trace_exporter))\n",
    "set_tracer_provider(tracer_provider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exporters = []\n",
    "exporters.append(AzureMonitorMetricExporter.from_connection_string(os.getenv(\"APPLICATIONINSIGHTS_CONNECTION_STRING\")))\n",
    "\n",
    "metric_readers = [PeriodicExportingMetricReader(exporter, export_interval_millis=5000) for exporter in exporters]\n",
    "\n",
    "meter_provider = MeterProvider(\n",
    "    metric_readers=metric_readers,\n",
    "    resource=telemetry_resource,\n",
    "    views=[\n",
    "        # Dropping all instrument names except for those starting with \"semantic_kernel\"\n",
    "        View(instrument_name=\"*\", aggregation=DropAggregation()),\n",
    "        View(instrument_name=\"semantic_kernel*\"),\n",
    "    ],\n",
    ")\n",
    "set_meter_provider(meter_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exporters = []\n",
    "exporters.append(AzureMonitorLogExporter(connection_string=os.getenv(\"APPLICATIONINSIGHTS_CONNECTION_STRING\")))\n",
    "\n",
    "\n",
    "logger_provider = LoggerProvider(resource=telemetry_resource)\n",
    "set_logger_provider(logger_provider)\n",
    "\n",
    "handler = LoggingHandler()\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.addHandler(handler)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "for log_exporter in exporters:\n",
    "    logger_provider.add_log_record_processor(BatchLogRecordProcessor(log_exporter))\n",
    "\n",
    "# FILTER - WHAT NOT TO LOG\n",
    "class KernelFilter(logging.Filter):\n",
    "    \"\"\"A filter to not process records from semantic_kernel.\"\"\"\n",
    "\n",
    "    # These are the namespaces that we want to exclude from logging for the purposes of this notebook\n",
    "    namespaces_to_exclude: list[str] = [\n",
    "        # \"semantic_kernel.functions.kernel_plugin\",\n",
    "        \"semantic_kernel.prompt_template.kernel_prompt_template\",\n",
    "        # \"semantic_kernel.functions.kernel_function\",\n",
    "        \"azure.monitor.opentelemetry.exporter.export._base\",\n",
    "        \"azure.core.pipeline.policies.http_logging_policy\"\n",
    "    ]\n",
    "\n",
    "    def filter(self, record):\n",
    "        return not any([record.name.startswith(namespace) for namespace in self.namespaces_to_exclude])\n",
    "\n",
    "handler.addFilter(KernelFilter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define our individual agents\n",
    "Structured defintion of our agent personas that charcterises how the agents should operate and interact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_job_research_agent_persona = \"\"\"\n",
    "name: \"Web-Job-Research-Agent\"\n",
    "description: Tech job posting analyzer that extracts key requirements for applicants.\n",
    "temperature: 0.1\n",
    "included_plugins: []\n",
    "instructions: |\n",
    "  Extract essential information from job postings to help with application preparation:\n",
    "    1. Scrape the provided job posting URL using scrape_website tool\n",
    "    2. Identify and categorize requirements into:\n",
    "    - Technical Skills (languages, tools, platforms)\n",
    "    - Soft Skills (communication, teamwork)\n",
    "    - Experience (years, specific domains)\n",
    "    - Education (degrees, certifications)\n",
    "    - Company Values/Culture\n",
    "    3. Highlight any must-have qualifications vs. preferred or nice to have qualifications\n",
    "    Focus on extracting actionable information that helps tailor resumes.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_reviewer_persona = f\"\"\"\n",
    "name: \"Resume-Reviewer-Agent\"\n",
    "description: Analyzes resume-job fit and provides targeted improvement recommendations.\n",
    "temperature: 0.1\n",
    "included_plugins: []\n",
    "instructions: |\n",
    "  Evaluate how well a candidate's resume aligns with job requirements from {WEB_JOB_RESEARCH_AGENT_NAME}:\n",
    "  \n",
    "  1. First, you will load the resume.\n",
    "  1. Review the uploaded resume against the job posting summary\n",
    "  2. Identify gaps between resume content and job requirements\n",
    "  3. Provide concise, specific, actionable recommendations to improve:\n",
    "     - Skills alignment (missing technical/soft skills)\n",
    "     - Experience presentation (achievements, metrics, relevance)\n",
    "     - Keywords/terminology matching\n",
    "     - Overall format and impact\n",
    "  4. Track previously suggested changes - never repeat recommendations\n",
    "  5. Verify if prior suggestions were implemented\n",
    "  6. Only suggest changes grounded in both the resume and job requirements\n",
    "  7. Do not make direct edits to the resume\n",
    "  8. When no further improvements needed, respond only with: {RESUME_REVIEW_COMPLETE_KEYWORD}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_copywriter_persona = f\"\"\"\n",
    "name: \"Resume-Copywriter-Agent\"\n",
    "description: Implements targeted resume improvements based on reviewer recommendations.\n",
    "temperature: 0.1\n",
    "included_plugins: []\n",
    "instructions: |\n",
    "  Update candidate resumes based on expert recommendations:\n",
    "  \n",
    "  1. Review improvement suggestions from {RESUME_REVIEWER_AGENT_NAME}\n",
    "  2. Implement changes to the resume focusing on:\n",
    "     - Enhancing relevance to job requirements\n",
    "     - Highlighting transferable skills\n",
    "     - Strengthening achievement statements with metrics\n",
    "     - Incorporating job-specific keywords\n",
    "     - Improving clarity and impact\n",
    "  3. Ground your updates on the candidate's original experience and qualifications\n",
    "  4. Preserve the resume's formatting structure\n",
    "  5. Return the complete updated resume with changes implemented\n",
    "  \n",
    "  Your goal is to transform the resume to maximize the candidate's chances of passing automated screening and impressing human reviewers.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interview_preparation_persona = f\"\"\"\n",
    "name: \"Interview-Preparation-Agent\"\n",
    "description: Create interview questions and talking points based on updated resume and job requirements\n",
    "temperature: 0.2\n",
    "included_plugins: []\n",
    "instructions: |\n",
    "  Your role is to prepare candidates to ensure they can confidently address all aspects of the job they are applying for by:\n",
    "  \n",
    "  1. Analyzing both the job posting requirements and the candidate's final updated resume deemed {RESUME_REVIEW_COMPLETE_KEYWORD} by {RESUME_REVIEWER_AGENT_NAME}\n",
    "  2. Create likely technical interview questions based on the job posting's requirements\n",
    "  3. Develop talking points that highlight how the candidate's experience aligns with job requirements\n",
    "  4. Prepare candidate responses for potential questions about gaps or missing requirements\n",
    "  5. Formulate examples of behavioral questions specific to the role\n",
    "  6. Suggest discussion points about company culture and values\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebJobResearchAgentPlugin:\n",
    "    def __init__(self):\n",
    "        pass  \n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Fetch a job posting from the Web using a url\", \n",
    "    )\n",
    "    async def fetch_job_posting(self, url:Annotated[str,\"The url of the job posting\"]) -> Annotated[str, \"The output in str format\"]:\n",
    "        \"\"\"\n",
    "        Fetch the job posting from the provided URL and analyze it to extract key skills, experiences, and qualifications required.\n",
    "\n",
    "        Parameters:\n",
    "        url (str): The URL of the job posting to analyze.\n",
    "\n",
    "        Returns:\n",
    "        str: A structured list of job requirements, including necessary skills, qualifications, and experiences.\n",
    "        \"\"\"\n",
    "        if USE_MOCK_JOB_POSTING:\n",
    "            try:\n",
    "                with open(MOCK_JOB_POSTING_PATH, 'r', encoding='utf-8') as file:\n",
    "                    content = file.read()\n",
    "                logging.info(f\"Successfully loaded mock job posting from {MOCK_JOB_POSTING_PATH}. Length: {len(content)} characters\")\n",
    "                               \n",
    "                if len(content) > JOB_POSTING_MAX_LENGTH:\n",
    "                    logging.info(f\"Truncating mock content from {len(content)} to {JOB_POSTING_MAX_LENGTH} characters\")\n",
    "                    content = content[:JOB_POSTING_MAX_LENGTH]\n",
    "                \n",
    "                return content\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed to load mock job posting: {str(e)}\")\n",
    "                # Fall back to web scraping if mock fails\n",
    "                pass\n",
    "            \n",
    "        # Continue with web scraping if not using mock or if mock loading failed\n",
    "        try:\n",
    "            headers = {\n",
    "                \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "                \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "                \"Accept-Language\": \"en-US,en;q=0.5\",\n",
    "                \"Connection\": \"keep-alive\",\n",
    "                \"Upgrade-Insecure-Requests\": \"1\",\n",
    "                \"Cache-Control\": \"max-age=0\"\n",
    "            }\n",
    "        \n",
    "            # Fetch the HTML content with a timeout\n",
    "            response = requests.get(url, headers=headers, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            html_content = response.text\n",
    "            logging.info(f\"Fetched {len(html_content)} characters from {url}\")\n",
    "            \n",
    "            # Now we want to parse the HTML to remove unnecessary elements, which save us a huge amount of LLM tokens\n",
    "            soup = BeautifulSoup(html_content, 'html.parser')\n",
    "            \n",
    "            # Remove script, style, and other non-content elements\n",
    "            for element in soup(['script', 'style', 'head', 'meta', 'link', 'noscript', 'iframe']):\n",
    "                element.decompose()\n",
    "            \n",
    "            # Get all text and do further cleaning\n",
    "            text = soup.get_text(separator='\\n', strip=True)\n",
    "            text = re.sub(r'\\n\\s*\\n', '\\n\\n', text)\n",
    "            text = re.sub(r' +', ' ', text)\n",
    "            \n",
    "            # Remove very short lines that might be menu items or UI elements\n",
    "            lines = text.split('\\n')\n",
    "            filtered_lines = [line for line in lines if len(line.strip()) > 3]\n",
    "            text = '\\n'.join(filtered_lines)\n",
    "            \n",
    "            # Add URL reference\n",
    "            text = f\"Job posting from: {url}\\n\\n{text}\"\n",
    "\n",
    "            if len(text) > JOB_POSTING_MAX_LENGTH:\n",
    "                logging.info(f\"Truncating parsed content from {len(text)} to {JOB_POSTING_MAX_LENGTH} characters\")\n",
    "                text = text[:JOB_POSTING_MAX_LENGTH]\n",
    "            \n",
    "            logging.info(f\"Successfully extracted content. Length: {len(text)} characters\")\n",
    "            return text\n",
    "        except:\n",
    "            logging.error(f\"Failed to fetch the job posting from {url}.\")\n",
    "            return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResumeReviewerAgentPlugin:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Load a resume either from a provided file path or use a mock resume if no path is provided\",\n",
    "    )\n",
    "    async def load_resume(self, file_path: Annotated[str, \"Optional path to a resume file\"] = \"\") -> Annotated[str, \"The resume content\"]:\n",
    "        \"\"\"\n",
    "        Load a resume either from a provided file path or use a mock resume if no path is provided.\n",
    "\n",
    "        Parameters:\n",
    "        file_path (str): Optional path to a resume file. If empty, a mock resume will be used.\n",
    "\n",
    "        Returns:\n",
    "        str: The content of the resume.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if RESUME_PATH and RESUME_PATH.strip():\n",
    "                with open(RESUME_PATH, 'r') as file:\n",
    "                    resume_content = file.read()\n",
    "                logging.info(f\"Successfully loaded resume from {file_path}\")\n",
    "                return resume_content\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to load resume: {str(e)}\")\n",
    "            return f\"Error loading resume: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResumeCopywriterAgentPlugin:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InterviewPreparationAgentPlugin:\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agent(kernel, service_id, definition):\n",
    "\n",
    "    definition = yaml.safe_load(definition)\n",
    "    execution_settings=AzureChatPromptExecutionSettings(\n",
    "            temperature=definition.get('temperature', 0.5),\n",
    "            function_choice_behavior=FunctionChoiceBehavior.Auto(\n",
    "                filters={\"included_plugins\": definition.get('included_plugins', [])}\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    return ChatCompletionAgent(\n",
    "        service=kernel.get_service(service_id=service_id),\n",
    "        kernel=kernel,\n",
    "        arguments=KernelArguments(settings=execution_settings),\n",
    "        name=definition['name'],\n",
    "        description=definition['description'],\n",
    "        instructions=definition['instructions']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = Kernel(\n",
    "    services=[GPT4O_SERVICE],\n",
    "    plugins=[\n",
    "        KernelPlugin.from_object(plugin_instance=WebJobResearchAgentPlugin(), plugin_name=\"WebJobResearchAgent\"),\n",
    "        KernelPlugin.from_object(plugin_instance=ResumeReviewerAgentPlugin(), plugin_name=\"ResumeReviewerAgent\"),\n",
    "        ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create agent group chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_job_research_agent = create_agent(service_id=\"gpt-4o\",\n",
    "                                      kernel=kernel,\n",
    "                                      definition=web_job_research_agent_persona)\n",
    "\n",
    "resume_copywriter_agent = create_agent(service_id=\"gpt-4o\",\n",
    "                                       kernel=kernel,\n",
    "                                       definition=resume_copywriter_persona)\n",
    "\n",
    "resume_reviewer_agent = create_agent(service_id=\"gpt-4o\",\n",
    "                                     kernel=kernel,\n",
    "                                     definition=resume_reviewer_persona)\n",
    "\n",
    "interview_preparer_agent = create_agent(service_id=\"gpt-4o\",\n",
    "                                        kernel=kernel,\n",
    "                                        definition=interview_preparation_persona)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define which of the agents responds next in the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_function = KernelFunctionFromPrompt(\n",
    "        function_name=\"selection\",\n",
    "        prompt=f\"\"\"\n",
    "        Examine the provided RESPONSE and choose the next participant.\n",
    "        State only the name of the chosen participant without explanation.\n",
    "        Never choose the participant named in the RESPONSE.\n",
    "\n",
    "        Choose only from these participants:\n",
    "        - {WEB_JOB_RESEARCH_AGENT_NAME}\n",
    "        - {RESUME_REVIEWER_AGENT_NAME} \n",
    "        - {RESUME_COPYWRITER_AGENT_NAME}\n",
    "        - {INTERVIEW_PREPARATION_AGENT_NAME}\n",
    "\n",
    "        Abide by the following policy:\n",
    "        - If RESPONSE is user, it is {WEB_JOB_RESEARCH_AGENT_NAME}'s turn. It's VERY IMPORTANT you only choose {WEB_JOB_RESEARCH_AGENT_NAME} one time!\n",
    "        - If RESPONSE is by {WEB_JOB_RESEARCH_AGENT_NAME}, it is {RESUME_REVIEWER_AGENT_NAME}'s turn. It's VERY IMPORTANT there is a review by {RESUME_REVIEWER_AGENT_NAME} at least once.\n",
    "        - If RESPONSE is by {RESUME_REVIEWER_AGENT_NAME}, it is {RESUME_COPYWRITER_AGENT_NAME}'s turn. It's VERY IMPORTANT there is a contribution by {RESUME_COPYWRITER_AGENT_NAME} at least once.\n",
    "        - If RESPONSE is by {RESUME_COPYWRITER_AGENT_NAME} and contains the exact phrase \"{RESUME_REVIEW_COMPLETE_KEYWORD}\", make {INTERVIEW_PREPARATION_AGENT_NAME} the final participant.\n",
    "        - After {INTERVIEW_PREPARATION_AGENT_NAME} has provided interview preparation guidance, do not select any more participants and indicate \"{PROCESS_COMPLETE}\" instead.\n",
    "\n",
    "        RESPONSE:\n",
    "        {{{{$lastmessage}}}}\n",
    "        \"\"\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the conditions under which the conversation ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_termination_strategy(agents, final_agent, maximum_iterations):\n",
    "    \"\"\"\n",
    "    Create a chat termination strategy that terminates when the final agent is reached.\n",
    "    params:\n",
    "        agents: List of agents to trigger termination evaluation\n",
    "        final_agent: The agent that should trigger termination\n",
    "        maximum_iterations: Maximum number of iterations before termination\n",
    "    \"\"\"\n",
    "    class CompletionTerminationStrategy(TerminationStrategy):\n",
    "        async def should_agent_terminate(self, agent, history):\n",
    "            \"\"\"Terminate if the last actor is the Responder Agent.\"\"\"\n",
    "            logging.getLogger(__name__).debug(history[-1])\n",
    "            return (agent.name == final_agent.name)\n",
    "\n",
    "    return CompletionTerminationStrategy(agents=agents,\n",
    "                                            maximum_iterations=maximum_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise the multi-agent chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_group_chat = AgentGroupChat(\n",
    "    agents = [web_job_research_agent, resume_copywriter_agent, resume_reviewer_agent, interview_preparer_agent],\n",
    "    selection_strategy=KernelFunctionSelectionStrategy(\n",
    "            function=selection_function,\n",
    "            kernel=kernel,\n",
    "            result_parser=lambda result: str(result.value[0]) if result.value is not None else RESUME_REVIEWER_AGENT_NAME,\n",
    "            agent_variable_name=\"agents\",\n",
    "            history_variable_name=\"lastmessage\",\n",
    "        ),\n",
    "    termination_strategy=create_termination_strategy(\n",
    "                agents=[web_job_research_agent, resume_copywriter_agent, resume_reviewer_agent, interview_preparer_agent],\n",
    "                final_agent=interview_preparer_agent,\n",
    "                maximum_iterations=MAXIMUM_CHAT_ITERATIONS\n",
    "            ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Ignore INFO messages like **semantic_kernel.contents.chat_history - INFO - Could not parse prompt <...> as xml, treating as text, error was:**\n",
    "this is a known \"**feature**\" explained in the link below:\n",
    "\n",
    "https://github.com/microsoft/semantic-kernel/issues/10425"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the multi-agent chat conversation, with tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_messages = []\n",
    "conversation_messages.append({'role': 'user', 'name': 'user', 'content': \"https://jobs.lever.co/AIFund/29e4750a-61c1-4195-9a11-7889577e3d6f\"})\n",
    "\n",
    "chat_history = [\n",
    "    ChatMessageContent(\n",
    "        role=AuthorRole(d.get('role')),\n",
    "        name=d.get('name'),\n",
    "        content=d.get('content')\n",
    "    ) for d in filter(lambda m: m['role'] in (\"system\", \"developer\", \"assistant\", \"user\"), conversation_messages)\n",
    "]\n",
    "\n",
    "await agent_group_chat.add_chat_messages(chat_history)\n",
    "\n",
    "tracer = get_tracer(__name__)\n",
    "with tracer.start_as_current_span(\"AgenticChat\"):\n",
    "    async for _ in agent_group_chat.invoke():\n",
    "        pass\n",
    "\n",
    "response = list(reversed([item async for item in agent_group_chat.get_chat_messages()]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, res in enumerate(response):\n",
    "    print(f\"\\n--- Response {i} ---\")\n",
    "    print(f\"Role: {res.role.value}\")\n",
    "    print(f\"Name: {res.name if hasattr(res, 'name') and res.name else 'None'}\")\n",
    "    print(f\"Content: {res.content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
